{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd41adfe-3c58-4d1e-815d-7a1085a521bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hydra\n",
    "import os\n",
    "from omegaconf import DictConfig, OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae998ce-e17f-4870-b5f5-61eaaac963c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970301b6-aebc-464b-9b2c-927a380fe277",
   "metadata": {},
   "source": [
    "### Load Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd745bb7-4b36-4c3f-9b16-31980325b2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    import yaml\n",
    "    with open(config_path, \"r\") as f:\n",
    "        cfg=yaml.safe_load(f)\n",
    "    # cfg = pd.DataFrame.from_dict(cfg.items())\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d903fe35-49be-4480-a34f-10b8fd539755",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_training': True,\n",
       " 'gpu': True,\n",
       " 'all_tfrecords_path': '/home/quincy/data/bach_tfrecords',\n",
       " 'train_data_dir': '/home/quincy/data/bach_kf/fold_1/bach_fold_1_train.csv',\n",
       " 'val_data_dir': '/home/quincy/data/bach_kf/fold_1/bach_fold_1_val.csv',\n",
       " 'checkpoints_dir': '/home/quincy/exps/clam/h1/cv1',\n",
       " 'i_optimizer_name': 'Adam',\n",
       " 'b_optimizer_name': 'Adam',\n",
       " 'a_optimizer_name': 'Adam',\n",
       " 'i_loss_name': 'binary_crossentropy',\n",
       " 'b_loss_name': 'binary_crossentropy',\n",
       " 'c1': 0.95,\n",
       " 'c2': 0.05,\n",
       " 'att_gate': True,\n",
       " 'mut_ex': False,\n",
       " 'i_learn_rate': 0.0002,\n",
       " 'b_learn_rate': 0.0002,\n",
       " 'a_learn_rate': 0.0002,\n",
       " 'imf_norm_op': True,\n",
       " 'n_class': 2,\n",
       " 'top_k_percent': 0.2,\n",
       " 'm_clam_op': False,\n",
       " 'batch_size': 0,\n",
       " 'epochs': 50,\n",
       " 'att_only': False,\n",
       " 'net_size': 'small',\n",
       " 'dropout_rate': 0.5,\n",
       " 'dim_compress_features': 512}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args=load_config(config_path=\"/home/quincy/code/DP_BACH/clam_tf_module/configs/train.yaml\")\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51cbfdc-5a10-414b-8bc8-d738f68a6f68",
   "metadata": {},
   "source": [
    "### Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2023ea0c-d116-4898-88b1-b5bda7b79e0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class G_Att_Net(tf.keras.Model):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        tf (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "        dim_features=1024,\n",
    "        n_hidden_units=256,\n",
    "    ):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            args (_type_): _description_\n",
    "            dim_features (int, optional): _description_. Defaults to 1024.\n",
    "            n_hidden_units (int, optional): _description_. Defaults to 256.\n",
    "        \"\"\"\n",
    "        super(G_Att_Net, self).__init__()\n",
    "        self.args = args\n",
    "        self.dim_features = dim_features\n",
    "        self.n_hidden_units = n_hidden_units\n",
    "\n",
    "        self.compression_model = tf.keras.models.Sequential()\n",
    "        self.model_v = tf.keras.models.Sequential()\n",
    "        self.model_u = tf.keras.models.Sequential()\n",
    "        self.model = tf.keras.models.Sequential()\n",
    "\n",
    "        self.fc_compress_layer = tf.keras.layers.Dense(\n",
    "            units=self.args[\"dim_compress_features\"],\n",
    "            activation=\"relu\",\n",
    "            input_shape=(self.dim_features,),\n",
    "            kernel_initializer=\"glorot_normal\",\n",
    "            bias_initializer=\"zeros\",\n",
    "            name=\"Fully_Connected_Layer\",\n",
    "        )\n",
    "\n",
    "        self.compression_model.add(self.fc_compress_layer)\n",
    "\n",
    "        self.att_v_layer1 = tf.keras.layers.Dense(\n",
    "            units=n_hidden_units,\n",
    "            activation=\"linear\",\n",
    "            input_shape=(self.args[\"dim_compress_features\"],),\n",
    "            kernel_initializer=\"glorot_normal\",\n",
    "            bias_initializer=\"zeros\",\n",
    "            name=\"Attention_V_Layer1\",\n",
    "        )\n",
    "\n",
    "        self.att_v_layer2 = tf.keras.layers.Dense(\n",
    "            units=n_hidden_units,\n",
    "            activation=\"tanh\",\n",
    "            input_shape=(self.args[\"dim_compress_features\"],),\n",
    "            kernel_initializer=\"glorot_normal\",\n",
    "            bias_initializer=\"zeros\",\n",
    "            name=\"Attention_V_Layer2\",\n",
    "        )\n",
    "\n",
    "        self.att_u_layer1 = tf.keras.layers.Dense(\n",
    "            units=n_hidden_units,\n",
    "            activation=\"linear\",\n",
    "            input_shape=(self.args[\"dim_compress_features\"],),\n",
    "            kernel_initializer=\"glorot_normal\",\n",
    "            bias_initializer=\"zeros\",\n",
    "            name=\"Attention_U_Layer1\",\n",
    "        )\n",
    "\n",
    "        self.att_u_layer2 = tf.keras.layers.Dense(\n",
    "            units=n_hidden_units,\n",
    "            activation=\"sigmoid\",\n",
    "            input_shape=(self.args[\"dim_compress_features\"],),\n",
    "            kernel_initializer=\"glorot_normal\",\n",
    "            bias_initializer=\"zeros\",\n",
    "            name=\"Attention_U_Layer2\",\n",
    "        )\n",
    "\n",
    "        self.att_layer_f = tf.keras.layers.Dense(\n",
    "            units=self.args[\"n_class\"],\n",
    "            activation=\"linear\",\n",
    "            input_shape=(n_hidden_units,),\n",
    "            kernel_initializer=\"glorot_normal\",\n",
    "            bias_initializer=\"zeros\",\n",
    "            name=\"Attention_Gated_Final_Layer\",\n",
    "        )\n",
    "\n",
    "        self.model_v.add(self.att_v_layer1)\n",
    "        self.model_v.add(self.att_v_layer2)\n",
    "\n",
    "        self.model_u.add(self.att_u_layer1)\n",
    "        self.model_u.add(self.att_u_layer2)\n",
    "\n",
    "        if self.args[\"dropout_rate\"] > 0.0:\n",
    "            self.model_v.add(\n",
    "                tf.keras.layers.Dropout(self.args[\"dropout_rate\"], name=\"Dropout_V_Layer\")\n",
    "            )\n",
    "            self.model_u.add(\n",
    "                tf.keras.layers.Dropout(self.args[\"dropout_rate\"], name=\"Dropout_U_Layer\")\n",
    "            )\n",
    "\n",
    "        self.model.add(self.att_layer_f)\n",
    "\n",
    "    def att_model(self):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        attention_model = [\n",
    "            self.compression_model,\n",
    "            self.model_v,\n",
    "            self.model_u,\n",
    "            self.model,\n",
    "        ]\n",
    "        return attention_model\n",
    "\n",
    "    def call(self, img_features):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            img_features (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        h = list()\n",
    "        A = list()\n",
    "\n",
    "        for i in img_features:\n",
    "            c_imf = self.att_model()[0](i)\n",
    "            h.append(c_imf)\n",
    "\n",
    "        for j in h:\n",
    "            att_v_output = self.att_model()[1](j)\n",
    "            att_u_output = self.att_model()[2](j)\n",
    "            att_input = tf.math.multiply(att_v_output, att_u_output)\n",
    "            a = self.att_model()[3](att_input)\n",
    "            A.append(a)\n",
    "\n",
    "        return {\"h\": h, \"A\": A}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec560b12-4400-4dc9-963a-7cf5306dfc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = G_Att_Net(args,dim_features=1024,\n",
    "        n_hidden_units=256,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a34770-6555-4db5-98a6-65cb9c77b6aa",
   "metadata": {},
   "source": [
    "### Instance Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83309680-a836-485d-9870-c549584a56d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Ins(tf.keras.Model):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        tf (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "    ):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            args (_type_): _description_\n",
    "        \"\"\"\n",
    "        super(Ins, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.ins_model = list()\n",
    "        self.m_ins_model = tf.keras.models.Sequential()\n",
    "        self.m_ins_layer = tf.keras.layers.Dense(\n",
    "            units=self.args[\"n_class\"],\n",
    "            activation=\"linear\",\n",
    "            input_shape=(self.args[\"dim_compress_features\"],),\n",
    "            name=\"Instance_Classifier_Layer\",\n",
    "        )\n",
    "        self.m_ins_model.add(self.m_ins_layer)\n",
    "\n",
    "        for i in range(self.args[\"n_class\"]):\n",
    "            self.ins_model.append(self.m_ins_model)\n",
    "\n",
    "    def ins_classifier(self):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        return self.ins_model\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_pos_labels(n_pos_sample):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n_pos_sample (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        return tf.fill(\n",
    "            dims=[\n",
    "                n_pos_sample,\n",
    "            ],\n",
    "            value=1,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_neg_labels(n_neg_sample):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n_neg_sample (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        return tf.fill(\n",
    "            dims=[\n",
    "                n_neg_sample,\n",
    "            ],\n",
    "            value=0,\n",
    "        )\n",
    "\n",
    "    def in_call(self, n_ins, ins_classifier, h, A_I):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n_ins (_type_): _description_\n",
    "            ins_classifier (_type_): _description_\n",
    "            h (_type_): _description_\n",
    "            A_I (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        pos_label = self.generate_pos_labels(n_ins)\n",
    "        neg_label = self.generate_neg_labels(n_ins)\n",
    "        ins_label_in = tf.concat(values=[pos_label, neg_label], axis=0)\n",
    "        A_I = tf.reshape(tf.convert_to_tensor(A_I), (1, len(A_I)))\n",
    "\n",
    "        top_pos_ids = tf.math.top_k(A_I, n_ins)[1][-1]\n",
    "        pos_index = list()\n",
    "        for i in top_pos_ids:\n",
    "            pos_index.append(i)\n",
    "\n",
    "        pos_index = tf.convert_to_tensor(pos_index)\n",
    "        top_pos = list()\n",
    "        for i in pos_index:\n",
    "            top_pos.append(h[i])\n",
    "\n",
    "        top_neg_ids = tf.math.top_k(-A_I, n_ins)[1][-1]\n",
    "        neg_index = list()\n",
    "        for i in top_neg_ids:\n",
    "            neg_index.append(i)\n",
    "\n",
    "        neg_index = tf.convert_to_tensor(neg_index)\n",
    "        top_neg = list()\n",
    "        for i in neg_index:\n",
    "            top_neg.append(h[i])\n",
    "\n",
    "        ins_in = tf.concat(values=[top_pos, top_neg], axis=0)\n",
    "        logits_unnorm_in = list()\n",
    "        logits_in = list()\n",
    "\n",
    "        for i in range(self.args[\"n_class\"] * n_ins):\n",
    "            ins_score_unnorm_in = ins_classifier(ins_in[i])\n",
    "            logit_in = tf.math.softmax(ins_score_unnorm_in)\n",
    "            logits_unnorm_in.append(ins_score_unnorm_in)\n",
    "            logits_in.append(logit_in)\n",
    "\n",
    "        return ins_label_in, logits_unnorm_in, logits_in\n",
    "\n",
    "    def out_call(self, n_ins, ins_classifier, h, A_O):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n_ins (_type_): _description_\n",
    "            ins_classifier (_type_): _description_\n",
    "            h (_type_): _description_\n",
    "            A_O (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # get compressed 512-dimensional instance-level feature vectors for following use, denoted by h\n",
    "        A_O = tf.reshape(tf.convert_to_tensor(A_O), (1, len(A_O)))\n",
    "        top_pos_ids = tf.math.top_k(A_O, n_ins)[1][-1]\n",
    "        pos_index = list()\n",
    "        for i in top_pos_ids:\n",
    "            pos_index.append(i)\n",
    "\n",
    "        pos_index = tf.convert_to_tensor(pos_index)\n",
    "        top_pos = list()\n",
    "        for i in pos_index:\n",
    "            top_pos.append(h[i])\n",
    "\n",
    "        # mutually-exclusive -> top k instances w/ highest attention scores ==> false pos = neg\n",
    "        pos_ins_labels_out = self.generate_neg_labels(n_ins)\n",
    "        ins_label_out = pos_ins_labels_out\n",
    "\n",
    "        logits_unnorm_out = list()\n",
    "        logits_out = list()\n",
    "\n",
    "        for i in range(n_ins):\n",
    "            ins_score_unnorm_out = ins_classifier(top_pos[i])\n",
    "            logit_out = tf.math.softmax(ins_score_unnorm_out)\n",
    "            logits_unnorm_out.append(ins_score_unnorm_out)\n",
    "            logits_out.append(logit_out)\n",
    "\n",
    "        return ins_label_out, logits_unnorm_out, logits_out\n",
    "\n",
    "    def call(self, bag_label, h, A):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            bag_label (_type_): _description_\n",
    "            h (_type_): _description_\n",
    "            A (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        n_ins = self.args[\"top_k_percent\"] * len(h)\n",
    "        n_ins = int(n_ins)\n",
    "        # if n_ins computed above is less than 0, make n_ins be default be 8\n",
    "        if n_ins == 0:\n",
    "            n_ins += 8\n",
    "\n",
    "        for i in range(self.args[\"n_class\"]):\n",
    "            ins_classifier = self.ins_classifier()[i]\n",
    "            if i == bag_label:\n",
    "                A_I = list()\n",
    "                for j in range(len(A)):\n",
    "                    a_i = A[j][0][i]\n",
    "                    A_I.append(a_i)\n",
    "                ins_label_in, logits_unnorm_in, logits_in = self.in_call(\n",
    "                    n_ins, ins_classifier, h, A_I\n",
    "                )\n",
    "            else:\n",
    "                if self.args[\"mut_ex\"]:\n",
    "                    A_O = list()\n",
    "                    for j in range(len(A)):\n",
    "                        a_o = A[j][0][i]\n",
    "                        A_O.append(a_o)\n",
    "                    ins_label_out, logits_unnorm_out, logits_out = self.out_call(\n",
    "                        n_ins, ins_classifier, h, A_O\n",
    "                    )\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        if self.args[\"mut_ex\"]:\n",
    "            ins_labels = tf.concat(values=[ins_label_in, ins_label_out], axis=0)\n",
    "            ins_logits_unnorm = logits_unnorm_in + logits_unnorm_out\n",
    "            ins_logits = logits_in + logits_out\n",
    "        else:\n",
    "            ins_labels = ins_label_in\n",
    "            ins_logits_unnorm = logits_unnorm_in\n",
    "            ins_logits = logits_in\n",
    "\n",
    "        return {\n",
    "            \"ins_labels\": ins_labels,\n",
    "            \"ins_logits_unnorm\": ins_logits_unnorm,\n",
    "            \"ins_logits\": ins_logits,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0a4268f-48fd-48d6-bfae-f33e0af3442f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins = Ins(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a1096d-5371-42b8-94dd-2605c7962618",
   "metadata": {},
   "source": [
    "### Bag Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fa140b6-d3ec-4e0d-bdbb-742badbb7d1f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class S_Bag(tf.keras.Model):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        tf (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "    ):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            args (_type_): _description_\n",
    "        \"\"\"\n",
    "        super(S_Bag, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.s_bag_model = tf.keras.models.Sequential()\n",
    "        self.s_bag_layer = tf.keras.layers.Dense(\n",
    "            units=1,\n",
    "            activation=\"linear\",\n",
    "            input_shape=(self.args[\"n_class\"], self.args[\"dim_compress_features\"]),\n",
    "            name=\"Bag_Classifier_Layer\",\n",
    "        )\n",
    "        self.s_bag_model.add(self.s_bag_layer)\n",
    "\n",
    "    def bag_classifier(self):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        return self.s_bag_model\n",
    "\n",
    "    def h_slide(self, A, h):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            A (_type_): _description_\n",
    "            h (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # compute the slide-level representation aggregated per the attention score distribution for the mth class\n",
    "        SAR = list()\n",
    "        for i in range(len(A)):\n",
    "            sar = tf.linalg.matmul(tf.transpose(A[i]), h[i])  # shape be (2,512)\n",
    "            SAR.append(sar)\n",
    "        slide_agg_rep = tf.math.add_n(SAR)  # return h_[slide,m], shape be (2,512)\n",
    "        ## need to reshape slide_agg_rep be (1,2,512), which will be compatible with input layer dimension\n",
    "        if len(slide_agg_rep.shape) == 2:\n",
    "            slide_agg_rep = tf.reshape(\n",
    "                slide_agg_rep, (1, slide_agg_rep.shape[0], slide_agg_rep.shape[1])\n",
    "            )\n",
    "\n",
    "        return slide_agg_rep\n",
    "\n",
    "    def call(self, bag_label, A, h):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            bag_label (_type_): _description_\n",
    "            A (_type_): _description_\n",
    "            h (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        slide_agg_rep = self.h_slide(A, h)\n",
    "        bag_classifier = self.bag_classifier()\n",
    "        slide_score_unnorm = bag_classifier(slide_agg_rep)\n",
    "        slide_score_unnorm = tf.reshape(slide_score_unnorm, (1, self.args[\"n_class\"]))\n",
    "        Y_hat = tf.math.top_k(slide_score_unnorm, 1)[1][-1]\n",
    "        Y_prob = tf.math.softmax(\n",
    "            tf.reshape(slide_score_unnorm, (1, self.args[\"n_class\"]))\n",
    "        )  # shape be (1,2), predictions for each of the classes\n",
    "        predict_slide_label = np.argmax(Y_prob.numpy())\n",
    "\n",
    "        Y_true = tf.one_hot([bag_label], 2)\n",
    "\n",
    "        return {\n",
    "            \"slide_score_unnorm\": slide_score_unnorm,\n",
    "            \"Y_hat\": Y_hat,\n",
    "            \"Y_prob\": Y_prob,\n",
    "            \"predict_slide_label\": predict_slide_label,\n",
    "            \"Y_true\": Y_true,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bcde5d0-8013-4a5c-bc6c-c59297751488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bag=S_Bag(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d3f615-4ca0-4701-a00e-4224abd3e74d",
   "metadata": {},
   "source": [
    "### CLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5156c803-d0ee-4f73-8ec6-feb623dcc1ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class S_CLAM(tf.keras.Model):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        tf (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "    ):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            args (_type_): _description_\n",
    "        \"\"\"\n",
    "        super(S_CLAM, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.net_shape_dict = {\"small\": [1024, 512, 256], \"big\": [1024, 512, 384]}\n",
    "        self.net_shape = self.net_shape_dict[self.args[\"net_size\"]]\n",
    "\n",
    "        if self.args[\"att_gate\"]:\n",
    "            self.att_net = G_Att_Net(\n",
    "                args=self.args,\n",
    "                dim_features=self.net_shape[0],\n",
    "                n_hidden_units=self.net_shape[2],\n",
    "            )\n",
    "        else:\n",
    "            self.att_net = NG_Att_Net(\n",
    "                args=self.args,\n",
    "                dim_features=self.net_shape[0],\n",
    "                n_hidden_units=self.net_shape[2],\n",
    "            )\n",
    "\n",
    "        self.ins_net = Ins(\n",
    "            args=self.args,\n",
    "        )\n",
    "        self.bag_net = S_Bag(\n",
    "            args=self.args,\n",
    "        )\n",
    "\n",
    "    def networks(self):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        c_nets = {\n",
    "            \"a_net\": self.att_net,\n",
    "            \"i_net\": self.ins_net,\n",
    "            \"b_net\": self.bag_net,\n",
    "        }\n",
    "\n",
    "        return c_nets\n",
    "\n",
    "    def clam_model(self):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        att_model = self.att_net.att_model()\n",
    "        ins_classifier = self.ins_net.ins_classifier()\n",
    "        bag_classifier = self.bag_net.bag_classifier()\n",
    "\n",
    "        clam_model = {\n",
    "            \"att_model\": att_model,\n",
    "            \"ins_classifier\": ins_classifier,\n",
    "            \"bag_classifier\": bag_classifier,\n",
    "        }\n",
    "\n",
    "        return clam_model\n",
    "\n",
    "    def call(self, img_features, slide_label):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            img_features (_type_): original 1024-dimensional instance-level feature vectors\n",
    "            slide_label (_type_): ground-truth slide label, could be 0 or 1 for binary classification\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        att_net_dict = self.att_net.call(img_features)\n",
    "        (h, att_score) = (att_net_dict[\"h\"], att_net_dict[\"A\"])\n",
    "        A = tf.math.softmax(att_score)  # softmax on attention scores\n",
    "\n",
    "        if self.args[\"att_only\"]:\n",
    "            return att_score\n",
    "\n",
    "        ins_net_dict = self.ins_net.call(slide_label, h, A)\n",
    "\n",
    "        bag_net_dict = self.bag_net.call(slide_label, A, h)\n",
    "\n",
    "        return {\n",
    "            \"att_score\": att_score,\n",
    "            \"A\": A,\n",
    "            \"h\": h,\n",
    "            \"ins_labels\": ins_net_dict[\"ins_labels\"],\n",
    "            \"ins_logits_unnorm\": ins_net_dict[\"ins_logits_unnorm\"],\n",
    "            \"ins_logits\": ins_net_dict[\"ins_logits\"],\n",
    "            \"slide_score_unnorm\": bag_net_dict[\"slide_score_unnorm\"],\n",
    "            \"Y_prob\": bag_net_dict[\"Y_prob\"],\n",
    "            \"Y_hat\": bag_net_dict[\"Y_hat\"],\n",
    "            \"Y_true\": bag_net_dict[\"Y_true\"],\n",
    "            \"predict_slide_label\": bag_net_dict[\"predict_slide_label\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c90d777-b3ed-4559-8f46-bc74524c9748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clam = S_CLAM(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c4313-7f19-4142-8bed-d7049ac8c784",
   "metadata": {},
   "source": [
    "### Load TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c3a38f6-461d-4295-9522-6de917447c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_from_tf(\n",
    "    tf_path,\n",
    "    args,\n",
    "):\n",
    "    feature = {\n",
    "        \"height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"depth\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image/format\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_feature\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(tf_path)\n",
    "\n",
    "    def _parse_image_function(key):\n",
    "        return tf.io.parse_single_example(key, feature)\n",
    "\n",
    "    CLAM_dataset = tfrecord_dataset.map(_parse_image_function)\n",
    "\n",
    "    image_features = list()\n",
    "\n",
    "    for tfrecord_value in CLAM_dataset:\n",
    "        img_feature = tf.io.parse_tensor(tfrecord_value[\"image_feature\"], \"float32\")\n",
    "\n",
    "        if args[\"imf_norm_op\"]:\n",
    "            img_feature = tf.math.l2_normalize(img_feature)\n",
    "\n",
    "        slide_labels = tfrecord_value[\"label\"]\n",
    "        slide_label = int(slide_labels)\n",
    "\n",
    "        image_features.append(img_feature)\n",
    "    image_features = tf.convert_to_tensor(image_features)\n",
    "    return image_features, slide_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ce1eb3b-9f03-48f6-95ce-0165d96dc302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_features1, slide_label1 = get_data_from_tf(tf_path=os.path.join(args[\"all_tfrecords_path\"], \"Benign_b001.tif.tfrecords\"), args=args)\n",
    "image_features2, slide_label2 = get_data_from_tf(tf_path=os.path.join(args[\"all_tfrecords_path\"], \"Benign_b002.tif.tfrecords\"), args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f4e511e-086f-4ec9-a308-2fa66764760d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_features = [image_features1, image_features2]\n",
    "# image_features = tf.convert_to_tensor(image_features)\n",
    "# image_features.shape\n",
    "image_labels = [slide_label1, slide_label2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac198926-9f9f-4dbd-b4f2-32952b42ad12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {\n",
    "\"f\": image_features,\n",
    "\"l\": image_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "613a3b23-1859-49df-af58-8f5772c0d9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,l = d[\"f\"], d[\"l\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b60d22c1-3dea-4699-a3f5-40bd428deeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.04770432 -0.02885905  0.03580757 ... -0.03625662  0.02170119\n",
      "   -0.01594341]]\n",
      "\n",
      " [[-0.04828378 -0.03103301  0.03278226 ... -0.03719165  0.01908513\n",
      "   -0.01416116]]\n",
      "\n",
      " [[-0.04782384 -0.03494673  0.034795   ... -0.03757655  0.02054382\n",
      "   -0.01873459]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.05088389 -0.02966737  0.03198273 ... -0.04303918  0.01688325\n",
      "   -0.01034377]]\n",
      "\n",
      " [[-0.04771412 -0.03413296  0.03635693 ... -0.03302318  0.02247962\n",
      "   -0.01806119]]\n",
      "\n",
      " [[-0.04698806 -0.03595782  0.03680196 ... -0.03351949  0.02090824\n",
      "   -0.01440851]]], shape=(48, 1, 1024), dtype=float32) tf.Tensor(\n",
      "[[[-0.04684934 -0.03560995  0.03652195 ... -0.03152008  0.02395286\n",
      "   -0.02166679]]\n",
      "\n",
      " [[-0.04859848 -0.03001648  0.03324676 ... -0.04270793  0.01947537\n",
      "   -0.02428757]]\n",
      "\n",
      " [[-0.04545477 -0.02825014  0.03524903 ... -0.03711646  0.02121446\n",
      "   -0.01648372]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.04651819 -0.0304567   0.0355213  ... -0.03727447  0.02321582\n",
      "   -0.01662292]]\n",
      "\n",
      " [[-0.04652981 -0.03055941  0.03568071 ... -0.03823921  0.02248095\n",
      "   -0.01706632]]\n",
      "\n",
      " [[-0.05033234 -0.03676265  0.03569707 ... -0.03532676  0.02248125\n",
      "   -0.01836621]]], shape=(48, 1, 1024), dtype=float32)\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "for ff, ll in f,l:\n",
    "    print(ff, ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7598dcc1-f8a4-48a2-9f73-6b148a9bd8e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.G_Att_Net at 0x7f6528fd0b70>,\n",
       " <__main__.Ins at 0x7f6528ec8f60>,\n",
       " <__main__.S_Bag at 0x7f6528709cf8>,\n",
       " <__main__.S_CLAM at 0x7f652871db38>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att, ins, bag, clam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "543de6b9-c9c4-4260-881c-0ce2328cac22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 1024), found shape=(48, 1, 1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3217430/4187407991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0matt_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"h\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3217430/3453684377.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, img_features)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mc_imf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_imf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/clam/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/clam/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\u001b[0m\u001b[1;32m    264\u001b[0m                              \u001b[0;34m'incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                              \u001b[0;34mf'expected shape={spec.shape}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 1024), found shape=(48, 1, 1024)"
     ]
    }
   ],
   "source": [
    "att_dict = att.call(image_features)\n",
    "h, A = att_dict[\"h\"], att_dict[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba5593aa-6369-4fd3-a518-1a1428862272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h1 = tf.convert_to_tensor(h)\n",
    "A1 = tf.convert_to_tensor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d15f4ce-a576-4275-a70b-5c1b39b44afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins_dict = ins.call(slide_label, h1, A1)\n",
    "ins_labels, ins_unnorm_logits, ins_logits = ins_dict['ins_labels'], ins_dict['ins_logits_unnorm'], ins_dict['ins_logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2508c1e1-211e-4365-86ed-fa0fde6a09e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18, 2), dtype=float32, numpy=\n",
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_l11 = tf.one_hot(ins_l1, 2)\n",
    "ins_l11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08e475cc-9678-4fe4-851b-3babe8bc4522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins_l1 = tf.convert_to_tensor(ins_labels)\n",
    "ins_ulo1 = tf.convert_to_tensor(ins_unnorm_logits)\n",
    "ins_lo1 = tf.convert_to_tensor(ins_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1cc6bd5f-639c-45be-b88b-784dc57910a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bag_dict = bag.call(slide_label, A1, h1)\n",
    "y_true, y_prob = bag_dict[\"Y_true\"], bag_dict[\"Y_prob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e3c57c0-e1fd-4e29-9b79-9bd16c22b3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clam.call(image_features, slide_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb70b1eb-8e27-42e0-8e58-c7e173440e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins_loss = tf.keras.losses.binary_crossentropy(ins_l11, ins_lo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b72c0d6-b495-442c-a950-b059266dbf1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins_loss1 = tf.math.reduce_mean(ins_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb1e5a92-8999-449b-b991-1faeee5525dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6931622>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb9f7db2-5cfc-4e29-9099-41d06c7b8b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bag_loss = tf.keras.losses.binary_crossentropy(y_true, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "37ba899d-9c6f-42e9-886b-cf2ce86a4017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.6577803], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0e893c9-1b0b-4b5e-ba3e-1a96ed840e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssu, sp, yhat = bag_dict['slide_score_unnorm'], bag_dict['predict_slide_label'], bag_dict[\"Y_hat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "333faafe-61b4-425b-9a7f-bdc165550909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.0416797 , -0.03035028]], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8538860f-b55b-4312-a21b-3312f8ec43b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6ad0c65c-eeb8-4cbc-952e-7c882217cec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ed45820-d60c-4b21-a92d-96da2b027b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6577802896499634"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(bag_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d6cd3fc7-8b09-40d8-9107-b10dcb50372d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 48, 1, 1024])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.l2_normalize(image_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "33685669-900d-4a01-b008-a781276a7bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 48, 1, 1024])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9c67c-ffc4-4202-a891-85174ab2aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict{\"features\": image_features, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
