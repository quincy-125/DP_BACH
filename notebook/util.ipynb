{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import PIL\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import statistics\n",
    "import time\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Functions or Methods from Other Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from optimize_test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Self-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_tf(tf_path):\n",
    "    feature = {\n",
    "        \"height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"depth\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image/format\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_feature\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(tf_path)\n",
    "\n",
    "    def _parse_image_function(key):\n",
    "        return tf.io.parse_single_example(key, feature)\n",
    "\n",
    "    CLAM_dataset = tfrecord_dataset.map(_parse_image_function)\n",
    "\n",
    "    image_features = list()\n",
    "\n",
    "    for tfrecord_value in CLAM_dataset:\n",
    "        img_feature = tf.io.parse_tensor(tfrecord_value[\"image_feature\"], \"float32\")\n",
    "        slide_labels = tfrecord_value[\"label\"]\n",
    "        slide_label = int(slide_labels)\n",
    "        image_features.append(img_feature)\n",
    "\n",
    "    return image_features, slide_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    mf = max(set(List), key=List.count)\n",
    "    return mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_shut_up(no_warn_op=False):\n",
    "    if no_warn_op:\n",
    "        tf.get_logger().setLevel(\"ERROR\")\n",
    "    else:\n",
    "        print(\n",
    "            \"Are you sure you want to receive the annoying TensorFlow Warning Messages?\",\n",
    "            \"\\n\",\n",
    "            \"If not, check the value of your input prameter for this function and re-run it.\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Methods of All Models for Optimized Stored CLAM Model Testing Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ng_att_call(ng_att_net, img_features):\n",
    "    h = list()\n",
    "    A = list()\n",
    "\n",
    "    for i in img_features:\n",
    "        c_imf = ng_att_net[0](i)\n",
    "        h.append(c_imf)\n",
    "\n",
    "    for i in img_features:\n",
    "        a = ng_att_net[1](i)\n",
    "        A.append(a)\n",
    "    return h, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_att_call(g_att_net, img_features):\n",
    "    h = list()\n",
    "    A = list()\n",
    "\n",
    "    for i in img_features:\n",
    "        c_imf = g_att_net[0](i)\n",
    "        h.append(c_imf)\n",
    "\n",
    "    for i in img_features:\n",
    "        layer1_output = g_att_net[1](i)\n",
    "        layer2_output = g_att_net[2](i)\n",
    "        a = tf.math.multiply(layer1_output, layer2_output)\n",
    "        a = g_att_net[3](a)\n",
    "        A.append(a)\n",
    "\n",
    "    return h, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pos_labels(n_pos_sample):\n",
    "    return tf.fill(\n",
    "        dims=[\n",
    "            n_pos_sample,\n",
    "        ],\n",
    "        value=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neg_labels(n_neg_sample):\n",
    "    return tf.fill(\n",
    "        dims=[\n",
    "            n_neg_sample,\n",
    "        ],\n",
    "        value=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ins_in_call(ins_classifier, h, A_I, n_ins, n_class):\n",
    "    pos_label = generate_pos_labels(n_pos_sample=n_ins)\n",
    "    neg_label = generate_neg_labels(n_neg_sample=n_ins)\n",
    "    ins_label_in = tf.concat(values=[pos_label, neg_label], axis=0)\n",
    "\n",
    "    A_I = tf.reshape(tf.convert_to_tensor(A_I), (1, len(A_I)))\n",
    "\n",
    "    top_pos_ids = tf.math.top_k(A_I, n_ins)[1][-1]\n",
    "    pos_index = list()\n",
    "    for i in top_pos_ids:\n",
    "        pos_index.append(i)\n",
    "\n",
    "    pos_index = tf.convert_to_tensor(pos_index)\n",
    "    top_pos = list()\n",
    "    for i in pos_index:\n",
    "        top_pos.append(h[i])\n",
    "\n",
    "    top_neg_ids = tf.math.top_k(-A_I, n_ins)[1][-1]\n",
    "    neg_index = list()\n",
    "    for i in top_neg_ids:\n",
    "        neg_index.append(i)\n",
    "\n",
    "    neg_index = tf.convert_to_tensor(neg_index)\n",
    "    top_neg = list()\n",
    "    for i in neg_index:\n",
    "        top_neg.append(h[i])\n",
    "\n",
    "    ins_in = tf.concat(values=[top_pos, top_neg], axis=0)\n",
    "    logits_unnorm_in = list()\n",
    "    logits_in = list()\n",
    "\n",
    "    for i in range(n_class * n_ins):\n",
    "        ins_score_unnorm_in = ins_classifier(ins_in[i])\n",
    "        logit_in = tf.math.softmax(ins_score_unnorm_in)\n",
    "        logits_unnorm_in.append(ins_score_unnorm_in)\n",
    "        logits_in.append(logit_in)\n",
    "\n",
    "    return ins_label_in, logits_unnorm_in, logits_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ins_out_call(ins_classifier, h, A_O, n_ins):\n",
    "    # get compressed 512-dimensional instance-level feature vectors for following use, denoted by h\n",
    "    A_O = tf.reshape(tf.convert_to_tensor(A_O), (1, len(A_O)))\n",
    "\n",
    "    top_pos_ids = tf.math.top_k(A_O, n_ins)[1][-1]\n",
    "    pos_index = list()\n",
    "    for i in top_pos_ids:\n",
    "        pos_index.append(i)\n",
    "\n",
    "    pos_index = tf.convert_to_tensor(pos_index)\n",
    "    top_pos = list()\n",
    "    for i in pos_index:\n",
    "        top_pos.append(h[i])\n",
    "\n",
    "    # mutually-exclusive -> top k instances w/ highest attention scores ==> false pos = neg\n",
    "    pos_ins_labels_out = generate_neg_labels(n_neg_sample=n_ins)\n",
    "    ins_label_out = pos_ins_labels_out\n",
    "\n",
    "    logits_unnorm_out = list()\n",
    "    logits_out = list()\n",
    "\n",
    "    for i in range(n_ins):\n",
    "        ins_score_unnorm_out = ins_classifier(top_pos[i])\n",
    "        logit_out = tf.math.softmax(ins_score_unnorm_out)\n",
    "        logits_unnorm_out.append(ins_score_unnorm_out)\n",
    "        logits_out.append(logit_out)\n",
    "\n",
    "    return ins_label_out, logits_unnorm_out, logits_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ins_call(m_ins_classifier, bag_label, h, A, n_class, n_ins, mut_ex):\n",
    "    for i in range(n_class):\n",
    "        ins_classifier = m_ins_classifier[i]\n",
    "        if i == bag_label:\n",
    "            A_I = list()\n",
    "            for j in range(len(A)):\n",
    "                a_i = A[j][0][i]\n",
    "                A_I.append(a_i)\n",
    "            ins_label_in, logits_unnorm_in, logits_in = ins_in_call(\n",
    "                ins_classifier=ins_classifier,\n",
    "                h=h,\n",
    "                A_I=A_I,\n",
    "                n_ins=n_ins,\n",
    "                n_class=n_class,\n",
    "            )\n",
    "        else:\n",
    "            if mut_ex:\n",
    "                A_O = list()\n",
    "                for j in range(len(A)):\n",
    "                    a_o = A[j][0][i]\n",
    "                    A_O.append(a_o)\n",
    "                ins_label_out, logits_unnorm_out, logits_out = ins_out_call(\n",
    "                    ins_classifier=ins_classifier, h=h, A_O=A_O, n_ins=n_ins\n",
    "                )\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    if mut_ex:\n",
    "        ins_labels = tf.concat(values=[ins_label_in, ins_label_out], axis=0)\n",
    "        ins_logits_unnorm = logits_unnorm_in + logits_unnorm_out\n",
    "        ins_logits = logits_in + logits_out\n",
    "    else:\n",
    "        ins_labels = ins_label_in\n",
    "        ins_logits_unnorm = logits_unnorm_in\n",
    "        ins_logits = logits_in\n",
    "\n",
    "    return ins_labels, ins_logits_unnorm, ins_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_h_slide(A, h):\n",
    "    # compute the slide-level representation aggregated per the attention score distribution for the mth class\n",
    "    SAR = list()\n",
    "    for i in range(len(A)):\n",
    "        sar = tf.linalg.matmul(tf.transpose(A[i]), h[i])  # shape be (2,512)\n",
    "        SAR.append(sar)\n",
    "\n",
    "    slide_agg_rep = tf.math.add_n(SAR)  # return h_[slide,m], shape be (2,512)\n",
    "\n",
    "    return slide_agg_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_bag_call(bag_classifier, bag_label, A, h, n_class):\n",
    "    slide_agg_rep = bag_h_slide(A=A, h=h)\n",
    "\n",
    "    slide_score_unnorm = bag_classifier(slide_agg_rep)\n",
    "    slide_score_unnorm = tf.reshape(slide_score_unnorm, (1, n_class))\n",
    "\n",
    "    Y_hat = tf.math.top_k(slide_score_unnorm, 1)[1][-1]\n",
    "\n",
    "    Y_prob = tf.math.softmax(\n",
    "        tf.reshape(slide_score_unnorm, (1, n_class))\n",
    "    )  # shape be (1,2), predictions for each of the classes\n",
    "\n",
    "    predict_slide_label = np.argmax(Y_prob.numpy())\n",
    "\n",
    "    Y_true = tf.one_hot([bag_label], 2)\n",
    "\n",
    "    return slide_score_unnorm, Y_hat, Y_prob, predict_slide_label, Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_bag_in_call(bag_classifier, h_slide_I):\n",
    "    ssu_in = bag_classifier(h_slide_I)[0][0]\n",
    "\n",
    "    return ssu_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_bag_out_call(bag_classifier, h_slide_O):\n",
    "    ssu_out = bag_classifier(h_slide_O)[0][0]\n",
    "\n",
    "    return ssu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_bag_call(m_bag_classifier, bag_label, A, h, n_class, dim_compress_features):\n",
    "    slide_agg_rep = bag_h_slide(A=A, h=h)\n",
    "    # unnormalized slide-level score (s_[slide,m]) with uninitialized entries, shape be (1,num_of_classes)\n",
    "    slide_score_unnorm = tf.Variable(np.empty((1, n_class)), dtype=tf.float32)\n",
    "    slide_score_unnorm = tf.reshape(slide_score_unnorm, (1, n_class)).numpy()\n",
    "\n",
    "    # return s_[slide,m] (slide-level prediction scores)\n",
    "    for i in range(n_class):\n",
    "        bag_classifier = m_bag_classifier[i]\n",
    "        if i == bag_label:\n",
    "            h_slide_I = tf.reshape(slide_agg_rep[i], (1, dim_compress_features))\n",
    "            ssu_in = m_bag_in_call(bag_classifier=bag_classifier, h_slide_I=h_slide_I)\n",
    "        else:\n",
    "            h_slide_O = tf.reshape(slide_agg_rep[i], (1, dim_compress_features))\n",
    "            ssu_out = m_bag_out_call(bag_classifier=bag_classifier, h_slide_O=h_slide_O)\n",
    "\n",
    "    for i in range(n_class):\n",
    "        if i == bag_label:\n",
    "            slide_score_unnorm[0, i] = ssu_in\n",
    "        else:\n",
    "            slide_score_unnorm[0, i] = ssu_out\n",
    "    slide_score_unnorm = tf.convert_to_tensor(slide_score_unnorm)\n",
    "\n",
    "    Y_hat = tf.math.top_k(slide_score_unnorm, 1)[1][-1]\n",
    "    Y_prob = tf.math.softmax(slide_score_unnorm)\n",
    "    predict_slide_label = np.argmax(Y_prob.numpy())\n",
    "\n",
    "    Y_true = tf.one_hot([bag_label], 2)\n",
    "\n",
    "    return slide_score_unnorm, Y_hat, Y_prob, predict_slide_label, Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_clam_call(\n",
    "    att_net,\n",
    "    ins_net,\n",
    "    bag_net,\n",
    "    img_features,\n",
    "    slide_label,\n",
    "    n_class,\n",
    "    n_ins,\n",
    "    att_gate,\n",
    "    att_only,\n",
    "    mil_ins,\n",
    "    mut_ex,\n",
    "):\n",
    "    if att_gate:\n",
    "        h, A = g_att_call(g_att_net=att_net, img_features=img_features)\n",
    "    else:\n",
    "        h, A = ng_att_call(ng_att_net=att_net, img_features=img_features)\n",
    "    att_score = A  # output from attention network\n",
    "    A = tf.math.softmax(A)  # softmax on attention scores\n",
    "\n",
    "    if att_only:\n",
    "        return att_score\n",
    "\n",
    "    if mil_ins:\n",
    "        ins_labels, ins_logits_unnorm, ins_logits = ins_call(\n",
    "            m_ins_classifier=ins_net,\n",
    "            bag_label=slide_label,\n",
    "            h=h,\n",
    "            A=A,\n",
    "            n_class=n_class,\n",
    "            n_ins=n_ins,\n",
    "            mut_ex=mut_ex,\n",
    "        )\n",
    "\n",
    "    slide_score_unnorm, Y_hat, Y_prob, predict_slide_label, Y_true = s_bag_call(\n",
    "        bag_classifier=bag_net, bag_label=slide_label, A=A, h=h, n_class=n_class\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        att_score,\n",
    "        A,\n",
    "        h,\n",
    "        ins_labels,\n",
    "        ins_logits_unnorm,\n",
    "        ins_logits,\n",
    "        slide_score_unnorm,\n",
    "        Y_prob,\n",
    "        Y_hat,\n",
    "        Y_true,\n",
    "        predict_slide_label,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_clam_call(\n",
    "    att_net,\n",
    "    ins_net,\n",
    "    bag_net,\n",
    "    img_features,\n",
    "    slide_label,\n",
    "    n_class,\n",
    "    dim_compress_features,\n",
    "    n_ins,\n",
    "    att_gate,\n",
    "    att_only,\n",
    "    mil_ins,\n",
    "    mut_ex,\n",
    "):\n",
    "    if att_gate:\n",
    "        h, A = g_att_call(g_att_net=att_net, img_features=img_features)\n",
    "    else:\n",
    "        h, A = ng_att_call(ng_att_net=att_net, img_features=img_features)\n",
    "    att_score = A  # output from attention network\n",
    "    A = tf.math.softmax(A)  # softmax on attention scores\n",
    "\n",
    "    if att_only:\n",
    "        return att_score\n",
    "\n",
    "    if mil_ins:\n",
    "        ins_labels, ins_logits_unnorm, ins_logits = ins_call(\n",
    "            m_ins_classifier=ins_net,\n",
    "            bag_label=slide_label,\n",
    "            h=h,\n",
    "            A=A,\n",
    "            n_class=n_class,\n",
    "            n_ins=n_ins,\n",
    "            mut_ex=mut_ex,\n",
    "        )\n",
    "\n",
    "    slide_score_unnorm, Y_hat, Y_prob, predict_slide_label, Y_true = m_bag_call(\n",
    "        m_bag_classifier=bag_net,\n",
    "        bag_label=slide_label,\n",
    "        A=A,\n",
    "        h=h,\n",
    "        n_class=n_class,\n",
    "        dim_compress_features=dim_compress_features,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        att_score,\n",
    "        A,\n",
    "        h,\n",
    "        ins_labels,\n",
    "        ins_logits_unnorm,\n",
    "        ins_logits,\n",
    "        slide_score_unnorm,\n",
    "        Y_prob,\n",
    "        Y_hat,\n",
    "        Y_true,\n",
    "        predict_slide_label,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Restoring CLAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(\n",
    "    i_model,\n",
    "    b_model,\n",
    "    c_model,\n",
    "    i_model_dir,\n",
    "    b_model_dir,\n",
    "    c_model_dir,\n",
    "    n_class,\n",
    "    m_bag_op,\n",
    "    m_clam_op,\n",
    "    g_att_op,\n",
    "):\n",
    "    for i in range(n_class):\n",
    "        i_model.ins_classifier()[i].save(\n",
    "            os.path.join(i_model_dir, \"M_Ins\", \"Class_\" + str(i))\n",
    "        )\n",
    "\n",
    "    if m_bag_op:\n",
    "        for j in range(n_class):\n",
    "            b_model.bag_classifier()[j].save(\n",
    "                os.path.join(b_model_dir, \"M_Bag\", \"Class_\" + str(j))\n",
    "            )\n",
    "    else:\n",
    "        b_model.bag_classifier().save(os.path.join(b_model_dir, \"S_Bag\"))\n",
    "\n",
    "    clam_model_names = [\"_Att\", \"_Ins\", \"_Bag\"]\n",
    "\n",
    "    if m_clam_op:\n",
    "        if g_att_op:\n",
    "            att_nets = c_model.clam_model()[0]\n",
    "            for m in range(len(att_nets)):\n",
    "                att_nets[m].save(\n",
    "                    os.path.join(\n",
    "                        c_model_dir, \"G\" + clam_model_names[0], \"Model_\" + str(m + 1)\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            att_nets = c_model.clam_model()[0]\n",
    "            for m in range(len(att_nets)):\n",
    "                att_nets[m].save(\n",
    "                    os.path.join(\n",
    "                        c_model_dir, \"NG\" + clam_model_names[0], \"Model_\" + str(m + 1)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        for n in range(n_class):\n",
    "            ins_nets = c_model.clam_model()[1]\n",
    "            bag_nets = c_model.clam_model()[2]\n",
    "\n",
    "            ins_nets[n].save(\n",
    "                os.path.join(c_model_dir, \"M\" + clam_model_names[1], \"Class_\" + str(n))\n",
    "            )\n",
    "            bag_nets[n].save(\n",
    "                os.path.join(c_model_dir, \"M\" + clam_model_names[2], \"Class_\" + str(n))\n",
    "            )\n",
    "    else:\n",
    "        if g_att_op:\n",
    "            att_nets = c_model.clam_model()[0]\n",
    "            for m in range(len(att_nets)):\n",
    "                att_nets[m].save(\n",
    "                    os.path.join(\n",
    "                        c_model_dir, \"G\" + clam_model_names[0], \"Model_\" + str(m + 1)\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            att_nets = c_model.clam_model()[0]\n",
    "            for m in range(len(att_nets)):\n",
    "                att_nets[m].save(\n",
    "                    os.path.join(\n",
    "                        c_model_dir, \"NG\" + clam_model_names[0], \"Model_\" + str(m + 1)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        for n in range(n_class):\n",
    "            ins_nets = c_model.clam_model()[1]\n",
    "            ins_nets[n].save(\n",
    "                os.path.join(c_model_dir, \"M\" + clam_model_names[1], \"Class_\" + str(n))\n",
    "            )\n",
    "\n",
    "        c_model.clam_model()[2].save(\n",
    "            os.path.join(c_model_dir, \"S\" + clam_model_names[2])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(\n",
    "    i_model_dir, b_model_dir, c_model_dir, n_class, m_bag_op, m_clam_op, g_att_op\n",
    "):\n",
    "    i_trained_model = list()\n",
    "    for i in range(n_class):\n",
    "        m_ins_names = os.listdir(os.path.join(i_model_dir, \"M_Ins\"))\n",
    "        m_ins_names.sort()\n",
    "        m_ins_name = m_ins_names[i]\n",
    "        m_ins_model = tf.keras.models.load_model(\n",
    "            os.path.join(i_model_dir, \"M_Ins\", m_ins_name)\n",
    "        )\n",
    "        i_trained_model.append(m_ins_model)\n",
    "\n",
    "    if m_bag_op:\n",
    "        b_trained_model = list()\n",
    "        for j in range(n_class):\n",
    "            m_bag_names = os.listdir(os.path.join(b_model_dir, \"M_Bag\"))\n",
    "            m_bag_names.sort()\n",
    "            m_bag_name = m_bag_names[j]\n",
    "            m_bag_model = tf.keras.models.load_model(\n",
    "                os.path.join(b_model_dir, \"M_Bag\", m_bag_name)\n",
    "            )\n",
    "            b_trained_model.append(m_bag_model)\n",
    "    else:\n",
    "        s_bag_name = os.listdir(b_model_dir)[0]\n",
    "        b_trained_model = tf.keras.models.load_model(\n",
    "            os.path.join(b_model_dir, s_bag_name)\n",
    "        )\n",
    "\n",
    "    clam_model_names = [\"_Att\", \"_Ins\", \"_Bag\"]\n",
    "\n",
    "    trained_att_net = list()\n",
    "    trained_ins_classifier = list()\n",
    "    trained_bag_classifier = list()\n",
    "\n",
    "    c_trained_model = list()\n",
    "\n",
    "    if m_clam_op:\n",
    "        if g_att_op:\n",
    "            att_nets_dir = os.path.join(c_model_dir, \"G\" + clam_model_names[0])\n",
    "            for k in range(len(os.listdir(att_nets_dir))):\n",
    "                att_net = tf.keras.models.load_model(\n",
    "                    os.path.join(att_nets_dir, \"Model_\" + str(k + 1))\n",
    "                )\n",
    "                trained_att_net.append(att_net)\n",
    "        else:\n",
    "            att_nets_dir = os.path.join(c_model_dir, \"NG\" + clam_model_names[0])\n",
    "            for k in range(len(os.listdir(att_nets_dir))):\n",
    "                att_net = tf.keras.models.load_model(\n",
    "                    os.path.join(att_nets_dir, \"Model_\" + str(k + 1))\n",
    "                )\n",
    "                trained_att_net.append(att_net)\n",
    "\n",
    "        ins_nets_dir = os.path.join(c_model_dir, \"M\" + clam_model_names[1])\n",
    "        bag_nets_dir = os.path.join(c_model_dir, \"M\" + clam_model_names[2])\n",
    "\n",
    "        for m in range(n_class):\n",
    "            ins_net = tf.keras.models.load_model(\n",
    "                os.path.join(ins_nets_dir, \"Class_\" + str(m))\n",
    "            )\n",
    "            bag_net = tf.keras.models.load_model(\n",
    "                os.path.join(bag_nets_dir, \"Class_\" + str(m))\n",
    "            )\n",
    "\n",
    "            trained_ins_classifier.append(ins_net)\n",
    "            trained_bag_classifier.append(bag_net)\n",
    "\n",
    "        c_trained_model = [\n",
    "            trained_att_net,\n",
    "            trained_ins_classifier,\n",
    "            trained_bag_classifier,\n",
    "        ]\n",
    "    else:\n",
    "        if g_att_op:\n",
    "            att_nets_dir = os.path.join(c_model_dir, \"G\" + clam_model_names[0])\n",
    "            for k in range(len(os.listdir(att_nets_dir))):\n",
    "                att_net = tf.keras.models.load_model(\n",
    "                    os.path.join(att_nets_dir, \"Model_\" + str(k + 1))\n",
    "                )\n",
    "                trained_att_net.append(att_net)\n",
    "        else:\n",
    "            att_nets_dir = os.path.join(c_model_dir, \"NG\" + clam_model_names[0])\n",
    "            for k in range(len(os.listdir(att_nets_dir))):\n",
    "                att_net = tf.keras.models.load_model(\n",
    "                    os.path.join(att_nets_dir, \"Model_\" + str(k + 1))\n",
    "                )\n",
    "                trained_att_net.append(att_net)\n",
    "\n",
    "        ins_nets_dir = os.path.join(c_model_dir, \"M\" + clam_model_names[1])\n",
    "\n",
    "        for m in range(n_class):\n",
    "            ins_net = tf.keras.models.load_model(\n",
    "                os.path.join(ins_nets_dir, \"Class_\" + str(m))\n",
    "            )\n",
    "            trained_ins_classifier.append(ins_net)\n",
    "\n",
    "        bag_nets_dir = os.path.join(c_model_dir, \"S\" + clam_model_names[2])\n",
    "        trained_bag_classifier.append(tf.keras.models.load_model(bag_nets_dir))\n",
    "\n",
    "        c_trained_model = [\n",
    "            trained_att_net,\n",
    "            trained_ins_classifier,\n",
    "            trained_bag_classifier[0],\n",
    "        ]\n",
    "\n",
    "    return i_trained_model, b_trained_model, c_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
