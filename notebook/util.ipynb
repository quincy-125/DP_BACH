{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import PIL\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import statistics\n",
    "import time\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Functions or Methods from Other Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from optimize_test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Self-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_tf(tf_path):\n",
    "    feature = {'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "               'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "               'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "               'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "               'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "               'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "               'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "               'image_feature': tf.io.FixedLenFeature([], tf.string)}\n",
    "\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(tf_path)\n",
    "\n",
    "    def _parse_image_function(key):\n",
    "        return tf.io.parse_single_example(key, feature)\n",
    "\n",
    "    CLAM_dataset = tfrecord_dataset.map(_parse_image_function)\n",
    "\n",
    "    image_features = list()\n",
    "\n",
    "    for tfrecord_value in CLAM_dataset:\n",
    "        img_feature = tf.io.parse_tensor(tfrecord_value['image_feature'], 'float32')\n",
    "        slide_labels = tfrecord_value['label']\n",
    "        slide_label = int(slide_labels)\n",
    "        image_features.append(img_feature)\n",
    "\n",
    "    return image_features, slide_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    mf = max(set(List), key=List.count)\n",
    "    return mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_shut_up(no_warn_op=False):\n",
    "    if no_warn_op:\n",
    "        tf.get_logger().setLevel('ERROR')\n",
    "    else:\n",
    "        print('Are you sure you want to receive the annoying TensorFlow Warning Messages?', \\\n",
    "              '\\n', 'If not, check the value of your input prameter for this function and re-run it.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Methods of All Models for Optimized Stored CLAM Model Testing Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ng_att_call(ng_att_net, img_features):\n",
    "    h = list()\n",
    "    A = list()\n",
    "\n",
    "    for i in img_features:\n",
    "        c_imf = ng_att_net[0](i)\n",
    "        h.append(c_imf)\n",
    "\n",
    "    for i in img_features:\n",
    "        a = ng_att_net[1](i)\n",
    "        A.append(a)\n",
    "    return h, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_att_call(g_att_net, img_features):\n",
    "    h = list()\n",
    "    A = list()\n",
    "\n",
    "    for i in img_features:\n",
    "        c_imf = g_att_net[0](i)\n",
    "        h.append(c_imf)\n",
    "\n",
    "    for i in img_features:\n",
    "        layer1_output = g_att_net[1](i)\n",
    "        layer2_output = g_att_net[2](i)\n",
    "        a = tf.math.multiply(layer1_output, layer2_output)\n",
    "        a = g_att_net[3](a)\n",
    "        A.append(a)\n",
    "\n",
    "    return h, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pos_labels(n_pos_sample):\n",
    "    return tf.fill(dims=[n_pos_sample, ], value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neg_labels(n_neg_sample):\n",
    "    return tf.fill(dims=[n_neg_sample, ], value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ins_in_call(ins_classifier, h, A_I, n_ins, n_class):\n",
    "    pos_label = generate_pos_labels(n_pos_sample=n_ins)\n",
    "    neg_label = generate_neg_labels(n_neg_sample=n_ins)\n",
    "    ins_label_in = tf.concat(values=[pos_label, neg_label], axis=0)\n",
    "\n",
    "    A_I = tf.reshape(tf.convert_to_tensor(A_I), (1, len(A_I)))\n",
    "\n",
    "    top_pos_ids = tf.math.top_k(A_I, n_ins)[1][-1]\n",
    "    pos_index = list()\n",
    "    for i in top_pos_ids:\n",
    "        pos_index.append(i)\n",
    "\n",
    "    pos_index = tf.convert_to_tensor(pos_index)\n",
    "    top_pos = list()\n",
    "    for i in pos_index:\n",
    "        top_pos.append(h[i])\n",
    "\n",
    "    top_neg_ids = tf.math.top_k(-A_I, n_ins)[1][-1]\n",
    "    neg_index = list()\n",
    "    for i in top_neg_ids:\n",
    "        neg_index.append(i)\n",
    "\n",
    "    neg_index = tf.convert_to_tensor(neg_index)\n",
    "    top_neg = list()\n",
    "    for i in neg_index:\n",
    "        top_neg.append(h[i])\n",
    "\n",
    "    ins_in = tf.concat(values=[top_pos, top_neg], axis=0)\n",
    "    logits_unnorm_in = list()\n",
    "    logits_in = list()\n",
    "\n",
    "    for i in range(n_class * n_ins):\n",
    "        ins_score_unnorm_in = ins_classifier(ins_in[i])\n",
    "        logit_in = tf.math.softmax(ins_score_unnorm_in)\n",
    "        logits_unnorm_in.append(ins_score_unnorm_in)\n",
    "        logits_in.append(logit_in)\n",
    "\n",
    "    return ins_label_in, logits_unnorm_in, logits_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ins_out_call(ins_classifier, h, A_O, n_ins):\n",
    "    # get compressed 512-dimensional instance-level feature vectors for following use, denoted by h\n",
    "    A_O = tf.reshape(tf.convert_to_tensor(A_O), (1, len(A_O)))\n",
    "\n",
    "    top_pos_ids = tf.math.top_k(A_O, n_ins)[1][-1]\n",
    "    pos_index = list()\n",
    "    for i in top_pos_ids:\n",
    "        pos_index.append(i)\n",
    "\n",
    "    pos_index = tf.convert_to_tensor(pos_index)\n",
    "    top_pos = list()\n",
    "    for i in pos_index:\n",
    "        top_pos.append(h[i])\n",
    "\n",
    "    # mutually-exclusive -> top k instances w/ highest attention scores ==> false pos = neg\n",
    "    pos_ins_labels_out = generate_neg_labels(n_neg_sample=n_ins)\n",
    "    ins_label_out = pos_ins_labels_out\n",
    "\n",
    "    logits_unnorm_out = list()\n",
    "    logits_out = list()\n",
    "\n",
    "    for i in range(n_ins):\n",
    "        ins_score_unnorm_out = ins_classifier(top_pos[i])\n",
    "        logit_out = tf.math.softmax(ins_score_unnorm_out)\n",
    "        logits_unnorm_out.append(ins_score_unnorm_out)\n",
    "        logits_out.append(logit_out)\n",
    "\n",
    "    return ins_label_out, logits_unnorm_out, logits_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ins_call(m_ins_classifier, bag_label, h, A, n_class, n_ins, mut_ex):\n",
    "    for i in range(n_class):\n",
    "        ins_classifier = m_ins_classifier[i]\n",
    "        if i == bag_label:\n",
    "            A_I = list()\n",
    "            for j in range(len(A)):\n",
    "                a_i = A[j][0][i]\n",
    "                A_I.append(a_i)\n",
    "            ins_label_in, logits_unnorm_in, logits_in = ins_in_call(ins_classifier=ins_classifier,\n",
    "                                                                    h=h, A_I=A_I, n_ins=n_ins,\n",
    "                                                                    n_class=n_class)\n",
    "        else:\n",
    "            if mut_ex:\n",
    "                A_O = list()\n",
    "                for j in range(len(A)):\n",
    "                    a_o = A[j][0][i]\n",
    "                    A_O.append(a_o)\n",
    "                ins_label_out, logits_unnorm_out, logits_out = ins_out_call(ins_classifier=ins_classifier,\n",
    "                                                                            h=h, A_O=A_O, n_ins=n_ins)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    if mut_ex:\n",
    "        ins_labels = tf.concat(values=[ins_label_in, ins_label_out], axis=0)\n",
    "        ins_logits_unnorm = logits_unnorm_in + logits_unnorm_out\n",
    "        ins_logits = logits_in + logits_out\n",
    "    else:\n",
    "        ins_labels = ins_label_in\n",
    "        ins_logits_unnorm = logits_unnorm_in\n",
    "        ins_logits = logits_in\n",
    "\n",
    "    return ins_labels, ins_logits_unnorm, ins_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_h_slide(A, h):\n",
    "    # compute the slide-level representation aggregated per the attention score distribution for the mth class\n",
    "    SAR = list()\n",
    "    for i in range(len(A)):\n",
    "        sar = tf.linalg.matmul(tf.transpose(A[i]), h[i])  # shape be (2,512)\n",
    "        SAR.append(sar)\n",
    "\n",
    "    slide_agg_rep = tf.math.add_n(SAR)  # return h_[slide,m], shape be (2,512)\n",
    "\n",
    "    return slide_agg_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_bag_call(bag_classifier, bag_label, A, h, n_class):\n",
    "    slide_agg_rep = bag_h_slide(A=A, h=h)\n",
    "\n",
    "    slide_score_unnorm = bag_classifier(slide_agg_rep)\n",
    "    slide_score_unnorm = tf.reshape(slide_score_unnorm, (1, n_class))\n",
    "\n",
    "    Y_hat = tf.math.top_k(slide_score_unnorm, 1)[1][-1]\n",
    "\n",
    "    Y_prob = tf.math.softmax(tf.reshape(slide_score_unnorm,\n",
    "                             (1, n_class)))  # shape be (1,2), predictions for each of the classes\n",
    "\n",
    "    predict_slide_label = np.argmax(Y_prob.numpy())\n",
    "\n",
    "    Y_true = tf.one_hot([bag_label], 2)\n",
    "\n",
    "    return slide_score_unnorm, Y_hat, Y_prob, predict_slide_label, Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_bag_in_call(bag_classifier, h_slide_I):\n",
    "    ssu_in = bag_classifier(h_slide_I)[0][0]\n",
    "\n",
    "    return ssu_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_bag_out_call(bag_classifier, h_slide_O):\n",
    "    ssu_out = bag_classifier(h_slide_O)[0][0]\n",
    "\n",
    "    return ssu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_bag_call(m_bag_classifier, bag_label, A, h, n_class, dim_compress_features):\n",
    "    slide_agg_rep = bag_h_slide(A=A, h=h)\n",
    "    # unnormalized slide-level score (s_[slide,m]) with uninitialized entries, shape be (1,num_of_classes)\n",
    "    slide_score_unnorm = tf.Variable(np.empty((1, n_class)), dtype=tf.float32)\n",
    "    slide_score_unnorm = tf.reshape(slide_score_unnorm, (1, n_class)).numpy()\n",
    "\n",
    "    # return s_[slide,m] (slide-level prediction scores)\n",
    "    for i in range(n_class):\n",
    "        bag_classifier = m_bag_classifier[i]\n",
    "        if i == bag_label:\n",
    "            h_slide_I = tf.reshape(slide_agg_rep[i], (1, dim_compress_features))\n",
    "            ssu_in = m_bag_in_call(bag_classifier=bag_classifier, h_slide_I=h_slide_I)\n",
    "        else:\n",
    "            h_slide_O = tf.reshape(slide_agg_rep[i], (1, dim_compress_features))\n",
    "            ssu_out = m_bag_out_call(bag_classifier=bag_classifier, h_slide_O=h_slide_O)\n",
    "\n",
    "    for i in range(n_class):\n",
    "        if i == bag_label:\n",
    "            slide_score_unnorm[0, i] = ssu_in\n",
    "        else:\n",
    "            slide_score_unnorm[0, i] = ssu_out\n",
    "    slide_score_unnorm = tf.convert_to_tensor(slide_score_unnorm)\n",
    "\n",
    "    Y_hat = tf.math.top_k(slide_score_unnorm, 1)[1][-1]\n",
    "    Y_prob = tf.math.softmax(slide_score_unnorm)\n",
    "    predict_slide_label = np.argmax(Y_prob.numpy())\n",
    "\n",
    "    Y_true = tf.one_hot([bag_label], 2)\n",
    "\n",
    "    return slide_score_unnorm, Y_hat, Y_prob, predict_slide_label, Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_clam_call(att_net, ins_net, bag_net, img_features, slide_label,\n",
    "                n_class, n_ins, att_gate, att_only, mil_ins, mut_ex):\n",
    "    if att_gate:\n",
    "        h, A = g_att_call(g_att_net=att_net, img_features=img_features)\n",
    "    else:\n",
    "        h, A = ng_att_call(ng_att_net=att_net, img_features=img_features)\n",
    "    att_score = A  # output from attention network\n",
    "    A = tf.math.softmax(A)   # softmax on attention scores\n",
    "\n",
    "    if att_only:\n",
    "        return att_score\n",
    "\n",
    "    if mil_ins:\n",
    "        ins_labels, ins_logits_unnorm, ins_logits = ins_call(m_ins_classifier=ins_net, bag_label=slide_label,\n",
    "                                                             h=h, A=A, n_class=n_class, n_ins=n_ins, mut_ex=mut_ex)\n",
    "\n",
    "    slide_score_unnorm, Y_hat, Y_prob, predict_slide_label, Y_true = s_bag_call(bag_classifier=bag_net,\n",
    "                                                                                bag_label=slide_label,\n",
    "                                                                                A=A, h=h, n_class=n_class)\n",
    "\n",
    "    return att_score, A, h, ins_labels, ins_logits_unnorm, ins_logits, \\\n",
    "           slide_score_unnorm, Y_prob, Y_hat, Y_true, predict_slide_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_clam_call(att_net, ins_net, bag_net, img_features, slide_label,\n",
    "                n_class, dim_compress_features, n_ins, att_gate, att_only, mil_ins, mut_ex):\n",
    "    if att_gate:\n",
    "        h, A = g_att_call(g_att_net=att_net, img_features=img_features)\n",
    "    else:\n",
    "        h, A = ng_att_call(ng_att_net=att_net, img_features=img_features)\n",
    "    att_score = A  # output from attention network\n",
    "    A = tf.math.softmax(A)  # softmax on attention scores\n",
    "\n",
    "    if att_only:\n",
    "        return att_score\n",
    "\n",
    "    if mil_ins:\n",
    "        ins_labels, ins_logits_unnorm, ins_logits = ins_call(m_ins_classifier=ins_net, bag_label=slide_label,\n",
    "                                                             h=h, A=A, n_class=n_class, n_ins=n_ins, mut_ex=mut_ex)\n",
    "\n",
    "    slide_score_unnorm, Y_hat, Y_prob, \\\n",
    "    predict_slide_label, Y_true = m_bag_call(m_bag_classifier=bag_net, bag_label=slide_label,\n",
    "                                             A=A, h=h, n_class=n_class,\n",
    "                                             dim_compress_features=dim_compress_features)\n",
    "\n",
    "    return att_score, A, h, ins_labels, ins_logits_unnorm, ins_logits, \\\n",
    "           slide_score_unnorm, Y_prob, Y_hat, Y_true, predict_slide_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Restoring CLAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(i_model, b_model, c_model, i_model_dir, b_model_dir, c_model_dir, n_class, m_bag_op, m_clam_op, g_att_op):\n",
    "    for i in range(n_class):\n",
    "        i_model.ins_classifier()[i].save(os.path.join(i_model_dir, 'M_Ins', 'Class_' + str(i)))\n",
    "        \n",
    "    if m_bag_op:\n",
    "        for j in range(n_class):\n",
    "            b_model.bag_classifier()[j].save(os.path.join(b_model_dir, 'M_Bag', 'Class_' + str(j)))\n",
    "    else:\n",
    "        b_model.bag_classifier().save(os.path.join(b_model_dir, 'S_Bag'))\n",
    "    \n",
    "    clam_model_names = ['_Att', '_Ins', '_Bag']\n",
    "                                         \n",
    "    if m_clam_op:                                 \n",
    "        if g_att_op:\n",
    "            att_nets = c_model.clam_model()[0]\n",
    "            for m in range(len(att_nets)):\n",
    "                att_nets[m].save(os.path.join(c_model_dir, 'G' + clam_model_names[0], 'Model_' + str(m + 1)))\n",
    "        else:\n",
    "            att_nets = c_model.clam_model()[0]\n",
    "            for m in range(len(att_nets)):\n",
    "                att_nets[m].save(os.path.join(c_model_dir, 'NG' + clam_model_names[0], 'Model_' + str(m + 1)))                             \n",
    "                                         \n",
    "        for n in range(n_class):\n",
    "            ins_nets = c_model.clam_model()[1]\n",
    "            bag_nets = c_model.clam_model()[2]\n",
    "            \n",
    "            ins_nets[n].save(os.path.join(c_model_dir, 'M' + clam_model_names[1], 'Class_' + str(n)))\n",
    "            bag_nets[n].save(os.path.join(c_model_dir, 'M' + clam_model_names[2], 'Class_' + str(n)))\n",
    "    else:\n",
    "        if g_att_op:\n",
    "            att_nets = c_model.clam_model()[0]\n",
    "            for m in range(len(att_nets)):\n",
    "                att_nets[m].save(os.path.join(c_model_dir, 'G' + clam_model_names[0], 'Model_' + str(m + 1)))\n",
    "        else:\n",
    "            att_nets = c_model.clam_model()[0]\n",
    "            for m in range(len(att_nets)):\n",
    "                att_nets[m].save(os.path.join(c_model_dir, 'NG' + clam_model_names[0], 'Model_' + str(m + 1)))\n",
    "                                         \n",
    "        for n in range(n_class):\n",
    "            ins_nets = c_model.clam_model()[1]\n",
    "            ins_nets[n].save(os.path.join(c_model_dir, 'M' + clam_model_names[1], 'Class_' + str(n)))\n",
    "        \n",
    "        c_model.clam_model()[2].save(os.path.join(c_model_dir, 'S' + clam_model_names[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(i_model_dir, b_model_dir, c_model_dir, n_class, m_bag_op, m_clam_op, g_att_op):\n",
    "    i_trained_model = list()\n",
    "    for i in range(n_class):\n",
    "        m_ins_names = os.listdir(os.path.join(i_model_dir, 'M_Ins'))\n",
    "        m_ins_names.sort()\n",
    "        m_ins_name = m_ins_names[i]\n",
    "        m_ins_model = tf.keras.models.load_model(os.path.join(i_model_dir, 'M_Ins', m_ins_name))\n",
    "        i_trained_model.append(m_ins_model)\n",
    "        \n",
    "    if m_bag_op:\n",
    "        b_trained_model = list()\n",
    "        for j in range(n_class):\n",
    "            m_bag_names = os.listdir(os.path.join(b_model_dir, 'M_Bag'))\n",
    "            m_bag_names.sort()\n",
    "            m_bag_name = m_bag_names[j]                                     \n",
    "            m_bag_model = tf.keras.models.load_model(os.path.join(b_model_dir, 'M_Bag', m_bag_name))\n",
    "            b_trained_model.append(m_bag_model)\n",
    "    else:\n",
    "        s_bag_name = os.listdir(b_model_dir)[0]\n",
    "        b_trained_model = tf.keras.models.load_model(os.path.join(b_model_dir, s_bag_name))\n",
    "    \n",
    "    clam_model_names = ['_Att', '_Ins', '_Bag']\n",
    " \n",
    "    trained_att_net = list()\n",
    "    trained_ins_classifier = list()\n",
    "    trained_bag_classifier = list()\n",
    "    \n",
    "    c_trained_model = list()\n",
    "    \n",
    "    if m_clam_op:\n",
    "        if g_att_op:\n",
    "            att_nets_dir = os.path.join(c_model_dir, 'G' + clam_model_names[0])\n",
    "            for k in range(len(os.listdir(att_nets_dir))):\n",
    "                att_net = tf.keras.models.load_model(os.path.join(att_nets_dir, 'Model_' + str(k+1)))\n",
    "                trained_att_net.append(att_net)\n",
    "        else:\n",
    "            att_nets_dir = os.path.join(c_model_dir, 'NG' + clam_model_names[0])\n",
    "            for k in range(len(os.listdir(att_nets_dir))):\n",
    "                att_net = tf.keras.models.load_model(os.path.join(att_nets_dir, 'Model_' + str(k+1)))\n",
    "                trained_att_net.append(att_net)\n",
    "        \n",
    "        ins_nets_dir = os.path.join(c_model_dir, 'M' + clam_model_names[1])\n",
    "        bag_nets_dir = os.path.join(c_model_dir, 'M' + clam_model_names[2])\n",
    "        \n",
    "        for m in range(n_class):\n",
    "            ins_net = tf.keras.models.load_model(os.path.join(ins_nets_dir, 'Class_' + str(m)))\n",
    "            bag_net = tf.keras.models.load_model(os.path.join(bag_nets_dir, 'Class_' + str(m)))\n",
    "            \n",
    "            trained_ins_classifier.append(ins_net)\n",
    "            trained_bag_classifier.append(bag_net)\n",
    "        \n",
    "        c_trained_model = [trained_att_net, trained_ins_classifier, trained_bag_classifier]\n",
    "    else:\n",
    "        if g_att_op:\n",
    "            att_nets_dir = os.path.join(c_model_dir, 'G' + clam_model_names[0])\n",
    "            for k in range(len(os.listdir(att_nets_dir))):\n",
    "                att_net = tf.keras.models.load_model(os.path.join(att_nets_dir, 'Model_' + str(k + 1)))\n",
    "                trained_att_net.append(att_net)\n",
    "        else:\n",
    "            att_nets_dir = os.path.join(c_model_dir, 'NG' + clam_model_names[0])\n",
    "            for k in range(len(os.listdir(att_nets_dir))):\n",
    "                att_net = tf.keras.models.load_model(os.path.join(att_nets_dir, 'Model_' + str(k + 1)))\n",
    "                trained_att_net.append(att_net)\n",
    "        \n",
    "        ins_nets_dir = os.path.join(c_model_dir, 'M' + clam_model_names[1])\n",
    "        \n",
    "        for m in range(n_class):\n",
    "            ins_net = tf.keras.models.load_model(os.path.join(ins_nets_dir, 'Class_' + str(m)))\n",
    "            trained_ins_classifier.append(ins_net)\n",
    "            \n",
    "        bag_nets_dir = os.path.join(c_model_dir, 'S' + clam_model_names[2])\n",
    "        trained_bag_classifier.append(tf.keras.models.load_model(bag_nets_dir))\n",
    "        \n",
    "        c_trained_model = [trained_att_net, trained_ins_classifier, trained_bag_classifier[0]]\n",
    "    \n",
    "    return i_trained_model, b_trained_model, c_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
